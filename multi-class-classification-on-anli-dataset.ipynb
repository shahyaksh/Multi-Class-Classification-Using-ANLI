{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets\n!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T15:23:40.724539Z","iopub.execute_input":"2025-12-10T15:23:40.724751Z","iopub.status.idle":"2025-12-10T15:23:51.990485Z","shell.execute_reply.started":"2025-12-10T15:23:40.724735Z","shell.execute_reply":"2025-12-10T15:23:51.989773Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.20.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyarrow-22.0.0\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datasets\nimport torch\nimport wandb\nfrom collections import Counter\nfrom datasets import load_dataset, concatenate_datasets\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification,\n    TrainingArguments, Trainer, DataCollatorWithPadding\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport os\nimport json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-11T21:20:47.704226Z","iopub.execute_input":"2025-12-11T21:20:47.704377Z","iopub.status.idle":"2025-12-11T21:21:46.291854Z","shell.execute_reply.started":"2025-12-11T21:20:47.704362Z","shell.execute_reply":"2025-12-11T21:21:46.291210Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-12-11 21:21:14.558781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765488074.967695      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765488075.079512      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"facebook/anli\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T21:21:46.293701Z","iopub.execute_input":"2025-12-11T21:21:46.294235Z","iopub.status.idle":"2025-12-11T21:21:53.401524Z","shell.execute_reply.started":"2025-12-11T21:21:46.294214Z","shell.execute_reply":"2025-12-11T21:21:53.400961Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ae839176c2445b8bf618dfd7815c5f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/train_r1-00000-of-00001.parqu(…):   0%|          | 0.00/3.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b137bc1b549451a8295b95e52759f26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/dev_r1-00000-of-00001.parquet:   0%|          | 0.00/351k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8c5719d020f4c7ead8fe65e3c6dfbad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/test_r1-00000-of-00001.parque(…):   0%|          | 0.00/353k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eb5fde8ce474c9f81bc5e14fad7a2e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/train_r2-00000-of-00001.parqu(…):   0%|          | 0.00/6.53M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098eb9ff7c824e4e8cc0f44d48d9f081"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/dev_r2-00000-of-00001.parquet:   0%|          | 0.00/351k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989beb4a795b4165a3c972a0009e1bb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/test_r2-00000-of-00001.parque(…):   0%|          | 0.00/362k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86d0971af0c945cbb5b69b09f31aa222"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/train_r3-00000-of-00001.parqu(…):   0%|          | 0.00/14.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96a4f44539f543ffa94d221239ea5385"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/dev_r3-00000-of-00001.parquet:   0%|          | 0.00/434k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06a727d15d3c49f58079a8aee2b64a9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/test_r3-00000-of-00001.parque(…):   0%|          | 0.00/435k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b74d7b4d472428f8e527c6823c94a28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_r1 split:   0%|          | 0/16946 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6cd431ca98c421e8bef155feb6e0424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev_r1 split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd8a64505974d1d94043aae85f0e05f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_r1 split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30c004a8981649caa89c6496b898dbc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_r2 split:   0%|          | 0/45460 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccfd6ef8b3484ba68982e9285bb30349"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev_r2 split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bda05dd11dd42b18f68d975195774f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_r2 split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac555442bd3042ec96db0531bde99b66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_r3 split:   0%|          | 0/100459 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c2ce367fc2e4222a0d5b375c914561e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev_r3 split:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c10c31a8f514511b75cc0043aaea038"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_r3 split:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03e8270771864911839ac9b6e24e88f1"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"wandb-key\")\nwandb.login(key=api_key)\nWANDB_PROJECT = \"EAI-Assignment-Multi-class-classification-using-ANLI\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T21:22:49.860532Z","iopub.execute_input":"2025-12-11T21:22:49.860857Z","iopub.status.idle":"2025-12-11T21:22:50.041450Z","shell.execute_reply.started":"2025-12-11T21:22:49.860836Z","shell.execute_reply":"2025-12-11T21:22:50.040889Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def load_combined_dataset(use_r1=True):\n    dataset = load_dataset(\"facebook/anli\")\n\n    train_data = dataset[\"train_r2\"]\n    val_data = dataset[\"dev_r2\"]\n    test_data = dataset[\"test_r2\"]\n\n    print(f\"R2 train: {len(train_data)} samples\")\n\n    if use_r1:\n        r1_train = dataset[\"train_r1\"]\n        train_data = concatenate_datasets([train_data, r1_train])\n        print(f\"+ R1: {len(r1_train)} samples added\")\n\n    print(f\"TOTAL training samples = {len(train_data)}\")\n    print(f\"Label distribution: {Counter(train_data['label'])}\")\n    \n    return train_data, val_data, test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T21:22:00.674018Z","iopub.execute_input":"2025-12-11T21:22:00.674537Z","iopub.status.idle":"2025-12-11T21:22:00.679292Z","shell.execute_reply.started":"2025-12-11T21:22:00.674512Z","shell.execute_reply":"2025-12-11T21:22:00.678610Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"OUTPUT_BASE = \"/kaggle/working/ANLI_Experiments\"\nos.makedirs(OUTPUT_BASE, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T16:20:26.761105Z","iopub.execute_input":"2025-12-11T16:20:26.761406Z","iopub.status.idle":"2025-12-11T16:20:26.765135Z","shell.execute_reply.started":"2025-12-11T16:20:26.761385Z","shell.execute_reply":"2025-12-11T16:20:26.764280Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"\n## 1. Configuration\n\nCentralized experiment settings using a Python dataclass. Handles all hyperparameters including model name, LoRA settings, learning rate, epochs, and dataset configuration. Automatically generates run names and sets sensible defaults based on whether LoRA is enabled.","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass ExperimentConfig:\n    \"\"\"Central configuration for experiment parameters.\"\"\"\n    model_name: str\n    use_lora: bool = True\n    lora_r: int = 16\n    lora_alpha: int = 32\n    lora_dropout: float = 0.1\n    dataset_config: str = \"r1_r2\"\n    learning_rate: Optional[float] = None\n    num_epochs: int = 5\n    max_length: int = 256\n    run_name: Optional[str] = None\n    tags: Optional[List[str]] = None\n    seed: int = 42\n    \n    def __post_init__(self):\n        if self.run_name is None:\n            model_short = self.model_name.split(\"/\")[-1]\n            lora_str = f\"lora-r{self.lora_r}\" if self.use_lora else \"full\"\n            self.run_name = f\"{model_short}-{lora_str}-{self.dataset_config}\"\n        \n        if self.learning_rate is None:\n            self.learning_rate = 2e-4 if self.use_lora else 2e-5\n        \n        if self.tags is None:\n            self.tags = [\"ANLI\", \"NLI\"]\n    \n    @property\n    def batch_size(self) -> int:\n        return 16 if self.use_lora else 8","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def setup_directories(output_base: str, run_name: str) -> Dict[str, str]:\n    \"\"\"Create and return experiment directory paths.\"\"\"\n    paths = {\n        \"output\": f\"{output_base}/{run_name}\",\n        \"checkpoints\": f\"{output_base}/{run_name}/checkpoints\",\n        \"final_model\": f\"{output_base}/{run_name}/final_model\",\n    }\n    \n    for path in paths.values():\n        os.makedirs(path, exist_ok=True)\n    \n    return paths","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Data Loading & Tokenization\n\nLoads the NLI dataset and applies tokenization using the model's tokenizer. Processes premise-hypothesis pairs with truncation, converts labels, and removes unnecessary columns. Returns train, validation, and test splits ready for training.","metadata":{}},{"cell_type":"code","source":"def load_and_tokenize_data(\n    tokenizer,\n    dataset_config: str,\n    max_length: int = 256,\n) -> Tuple[Any, Any, Any]:\n    \"\"\"Load dataset and apply tokenization.\"\"\"\n    \n    use_r1 = \"r1\" in dataset_config\n    train_data, val_data, test_data = load_combined_dataset(use_r1=use_r1)\n    \n    def tokenize_fn(examples):\n        enc = tokenizer(\n            examples[\"premise\"],\n            examples[\"hypothesis\"],\n            truncation=True,\n            max_length=max_length,\n        )\n        enc[\"labels\"] = examples[\"label\"]\n        return enc\n    \n    cols_remove = [\"uid\", \"premise\", \"hypothesis\", \"reason\"]\n    \n    train_tok = train_data.map(tokenize_fn, batched=True, remove_columns=cols_remove)\n    val_tok = val_data.map(tokenize_fn, batched=True, remove_columns=cols_remove)\n    test_tok = test_data.map(tokenize_fn, batched=True, remove_columns=cols_remove)\n    \n    return train_tok, val_tok, test_tok\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 3. Model Setup\n\nInitializes the base transformer model for sequence classification. When LoRA is enabled, applies parameter-efficient adapters targeting attention layers (query, key, value). Automatically detects DeBERTa models and adjusts target module names accordingly.","metadata":{}},{"cell_type":"code","source":"def load_base_model(model_name: str, num_labels: int = 3):\n    \"\"\"Load the base classification model.\"\"\"\n    return AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=num_labels,\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_lora(model, config: ExperimentConfig):\n    \"\"\"Apply LoRA adapters to the model.\"\"\"\n    if \"deberta\" in config.model_name.lower():\n        target_modules = [\"query_proj\", \"key_proj\", \"value_proj\"]\n    else:\n        target_modules = [\"query\", \"key\", \"value\"]\n    \n    lora_config = LoraConfig(\n        task_type=TaskType.SEQ_CLS,\n        r=config.lora_r,\n        lora_alpha=config.lora_alpha,\n        lora_dropout=config.lora_dropout,\n        target_modules=target_modules,\n        modules_to_save=[\"classifier\", \"pooler\"],\n    )\n    \n    model = get_peft_model(model, lora_config)\n    model.print_trainable_parameters()\n    \n    # Debug: verify classifier is trainable\n    for name, param in model.named_parameters():\n        if 'classifier' in name:\n            print(f\"  {name}: requires_grad={param.requires_grad}\")\n    \n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def setup_model(config: ExperimentConfig):\n    \"\"\"Load model and optionally apply LoRA.\"\"\"\n    model = load_base_model(config.model_name)\n    \n    if config.use_lora:\n        model = apply_lora(model, config)\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. W&B Initialization\n\nSets up Weights & Biases experiment tracking. Logs all configuration parameters, dataset sizes, and training hyperparameters. Enables real-time monitoring of training progress and metric visualization.","metadata":{}},{"cell_type":"code","source":"def init_wandb(\n    project: str,\n    config: ExperimentConfig,\n    train_size: int,\n    val_size: int,\n    test_size: int,\n) -> None:\n    \"\"\"Initialize Weights & Biases tracking.\"\"\"\n    wandb.init(\n        project=project,\n        name=config.run_name,\n        config={\n            \"model_name\": config.model_name,\n            \"use_lora\": config.use_lora,\n            \"lora_r\": config.lora_r if config.use_lora else None,\n            \"lora_alpha\": config.lora_alpha if config.use_lora else None,\n            \"dataset\": config.dataset_config,\n            \"train_samples\": train_size,\n            \"val_samples\": val_size,\n            \"test_samples\": test_size,\n            \"learning_rate\": config.learning_rate,\n            \"batch_size\": config.batch_size,\n            \"epochs\": config.num_epochs,\n            \"max_length\": config.max_length,\n        },\n        tags=config.tags,\n        reinit=True,\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Training Configuration\n\nBuilds HuggingFace TrainingArguments with optimized settings. Configures mixed-precision training, gradient accumulation, warmup schedule, and checkpoint saving strategy. Sets up epoch-based evaluation with F1-macro as the optimization target.","metadata":{}},{"cell_type":"code","source":"def create_training_args(config: ExperimentConfig, checkpoint_dir: str) -> TrainingArguments:\n    \"\"\"Create HuggingFace TrainingArguments.\"\"\"\n    return TrainingArguments(\n        output_dir=checkpoint_dir,\n        num_train_epochs=config.num_epochs,\n        \n        per_device_train_batch_size=config.batch_size,\n        per_device_eval_batch_size=config.batch_size * 2,\n        gradient_accumulation_steps=2,\n        \n        learning_rate=config.learning_rate,\n        weight_decay=0.01,\n        warmup_ratio=0.1,\n        \n        fp16=True,\n        optim=\"adamw_torch\",\n        \n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        save_total_limit=2,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1_macro\",\n        greater_is_better=True,\n        \n        logging_steps=50,\n        report_to=\"wandb\",\n        \n        seed=config.seed,\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 6. Metrics\n\nComputes evaluation metrics during training and testing. Calculates accuracy and macro-averaged F1 score. Also prints prediction distribution for debugging class imbalance issues.","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred) -> Dict[str, float]:\n    \"\"\"Compute accuracy and macro F1 for evaluation.\"\"\"\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    \n    unique, counts = np.unique(preds, return_counts=True)\n    pred_dist = dict(zip(unique.tolist(), counts.tolist()))\n    print(f\"  Pred distribution: {pred_dist}\")\n    \n    return {\n        \"accuracy\": accuracy_score(labels, preds),\n        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n    }\n\n\ndef generate_classification_report(labels, preds) -> Tuple[Dict, str]:\n    \"\"\"Generate classification report dict and string.\"\"\"\n    target_names = ['Entailment', 'Neutral', 'Contradiction']\n    \n    report_dict = classification_report(\n        labels, preds,\n        target_names=target_names,\n        output_dict=True\n    )\n    \n    report_str = classification_report(\n        labels, preds,\n        target_names=target_names\n    )\n    \n    return report_dict, report_str\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Training & Evaluation\n\nExecutes the training loop and runs final evaluation on the test set. Tracks training time, generates predictions, and produces a detailed classification report with per-class precision, recall, and F1 scores.","metadata":{}},{"cell_type":"code","source":"def create_trainer(\n    model,\n    training_args: TrainingArguments,\n    train_dataset,\n    val_dataset,\n    tokenizer,\n) -> Trainer:\n    \"\"\"Create and return the Trainer instance.\"\"\"\n    return Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        tokenizer=tokenizer,\n        data_collator=DataCollatorWithPadding(tokenizer),\n        compute_metrics=compute_metrics,\n    )\n\n\ndef train_model(trainer: Trainer) -> float:\n    \"\"\"Train the model and return training time in minutes.\"\"\"\n    start = time.time()\n    trainer.train()\n    return (time.time() - start) / 60","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(trainer: Trainer, test_dataset) -> Dict[str, Any]:\n    \"\"\"Run evaluation and return comprehensive results.\"\"\"\n    test_results = trainer.evaluate(test_dataset)\n    \n    predictions = trainer.predict(test_dataset)\n    preds = np.argmax(predictions.predictions, axis=-1)\n    labels = predictions.label_ids\n    \n    report_dict, report_str = generate_classification_report(labels, preds)\n    \n    print(f\"\\nTEST RESULTS → ACC={test_results['eval_accuracy']:.4f}, F1={test_results['eval_f1_macro']:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(report_str)\n    \n    return {\n        \"test_results\": test_results,\n        \"predictions\": preds,\n        \"labels\": labels,\n        \"report\": report_dict,\n    }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 8. Logging & Saving\n\nHandles all persistence operations after training completes. Logs final metrics and confusion matrix to W&B, saves model weights and tokenizer locally, writes results JSON, and uploads the trained model as a W&B artifact for versioning.","metadata":{}},{"cell_type":"code","source":"def log_final_metrics(eval_results: Dict, train_time: float) -> None:\n    \"\"\"Log final metrics to W&B.\"\"\"\n    report = eval_results[\"report\"]\n    test_results = eval_results[\"test_results\"]\n    \n    wandb.log({\n        \"test/accuracy\": test_results['eval_accuracy'],\n        \"test/f1_macro\": test_results['eval_f1_macro'],\n        \"test/f1_entailment\": report['Entailment']['f1-score'],\n        \"test/f1_neutral\": report['Neutral']['f1-score'],\n        \"test/f1_contradiction\": report['Contradiction']['f1-score'],\n        \"train_time_min\": train_time,\n    })\n    \n    wandb.log({\n        \"confusion_matrix\": wandb.plot.confusion_matrix(\n            y_true=eval_results[\"labels\"],\n            preds=eval_results[\"predictions\"],\n            class_names=['Entailment', 'Neutral', 'Contradiction']\n        )\n    })\n    \ndef save_model_and_results(\n    trainer: Trainer,\n    tokenizer,\n    paths: Dict[str, str],\n    run_name: str,\n    eval_results: Dict,\n    train_time: float,\n) -> None:\n    \"\"\"Save model, tokenizer, and results JSON.\"\"\"\n    print(f\"\\n Saving model to: {paths['final_model']}\")\n    \n    trainer.save_model(paths['final_model'])\n    tokenizer.save_pretrained(paths['final_model'])\n    \n    with open(f\"{paths['output']}/results.json\", 'w') as f:\n        json.dump({\n            \"run_name\": run_name,\n            \"test_accuracy\": eval_results[\"test_results\"]['eval_accuracy'],\n            \"test_f1_macro\": eval_results[\"test_results\"]['eval_f1_macro'],\n            \"train_time_min\": train_time,\n        }, f, indent=2)\n\n\ndef upload_wandb_artifact(\n    paths: Dict[str, str],\n    run_name: str,\n    model_name: str,\n    use_lora: bool,\n    eval_results: Dict,\n    dataset_config: str,\n) -> None:\n    \"\"\"Upload model to W&B Artifacts.\"\"\"\n    print(f\"\\n Uploading model to W&B Artifacts...\")\n    \n    test_results = eval_results[\"test_results\"]\n    \n    artifact = wandb.Artifact(\n        name=f\"model-{run_name}\",\n        type=\"model\",\n        description=f\"Fine-tuned {model_name} on ANLI {dataset_config}\",\n        metadata={\n            \"accuracy\": test_results['eval_accuracy'],\n            \"f1_macro\": test_results['eval_f1_macro'],\n            \"model_name\": model_name,\n            \"use_lora\": use_lora,\n        }\n    )\n    \n    artifact.add_dir(paths['final_model'])\n    wandb.log_artifact(artifact)\n    \n    print(f\" Model uploaded to W&B Artifacts: model-{run_name}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Main Orchestrator\n\nThe primary entry point that coordinates all modules in sequence. Takes experiment parameters, instantiates the config, and executes the full pipeline from data loading through model upload. Returns a summary dictionary with final metrics.","metadata":{}},{"cell_type":"code","source":"def run_experiment(\n    model_name: str,\n    output_base: str,\n    wandb_project: str,\n    use_lora: bool = True,\n    lora_r: int = 16,\n    lora_alpha: int = 32,\n    dataset_config: str = \"r1_r2\",\n    learning_rate: Optional[float] = None,\n    num_epochs: int = 5,\n    run_name: Optional[str] = None,\n    tags: Optional[List[str]] = None,\n) -> Dict[str, Any]:\n    \"\"\"\n    Main experiment orchestrator - coordinates all components.\n    \"\"\"\n    # Create config\n    config = ExperimentConfig(\n        model_name=model_name,\n        use_lora=use_lora,\n        lora_r=lora_r,\n        lora_alpha=lora_alpha,\n        dataset_config=dataset_config,\n        learning_rate=learning_rate,\n        num_epochs=num_epochs,\n        run_name=run_name,\n        tags=tags,\n    )\n    \n    print(f\"\\n{'='*60}\")\n    print(f\" Starting Run: {config.run_name}\")\n    print(f\"{'='*60}\")\n    \n    # Setup directories\n    paths = setup_directories(output_base, config.run_name)\n    \n    # Load tokenizer and data\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    train_tok, val_tok, test_tok = load_and_tokenize_data(\n        tokenizer, config.dataset_config, config.max_length\n    )\n    \n    # Setup model\n    model = setup_model(config)\n    \n    # Init W&B\n    init_wandb(wandb_project, config, len(train_tok), len(val_tok), len(test_tok))\n    \n    # Create training args and trainer\n    training_args = create_training_args(config, paths[\"checkpoints\"])\n    trainer = create_trainer(model, training_args, train_tok, val_tok, tokenizer)\n    \n    # Train\n    train_time = train_model(trainer)\n    \n    # Evaluate\n    eval_results = evaluate_model(trainer, test_tok)\n    \n    #  Log, save, upload\n    log_final_metrics(eval_results, train_time)\n    save_model_and_results(trainer, tokenizer, paths, config.run_name, eval_results, train_time)\n    upload_wandb_artifact(paths, config.run_name, model_name, use_lora, eval_results, config.dataset_config)\n    \n    # Cleanup\n    wandb.finish()\n    \n    return {\n        \"run_name\": config.run_name,\n        \"accuracy\": eval_results[\"test_results\"]['eval_accuracy'],\n        \"f1_macro\": eval_results[\"test_results\"]['eval_f1_macro'],\n        \"train_time\": train_time,\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"WANDB_RUN_NAME = \"deberta-base-lora-r16-r2\"\n\n\nresults = run_experiment(\n    model_name=\"microsoft/deberta-v3-base\",\n    use_lora=True,\n    lora_r=16,\n    dataset_config=\"r2\",\n    run_name=\"deberta-base-lora-r16-r2\",\n    tags=[\"DeBERTa\", \"LoRA\", \"R2\"],\n)\n\nprint(f\"\\nFINAL RESULTS: {results}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T16:20:35.790797Z","iopub.execute_input":"2025-12-11T16:20:35.791714Z","iopub.status.idle":"2025-12-11T17:23:00.681279Z","shell.execute_reply.started":"2025-12-11T16:20:35.791679Z","shell.execute_reply":"2025-12-11T17:23:00.680511Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\n Starting Run: deberta-base-lora-r16-r2\n============================================================\nR2 train: 45460 samples\nTOTAL training samples = 45460\nLabel distribution: Counter({1: 20959, 0: 14448, 2: 10053})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d753e2884c4346db96a01ddc523e9e4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca60c412bac341bdb2b245a4b1052cec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88ede602adc433ca783d0a1c64a484c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45460 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c057beb8b0f84e6f8092c44d86c25445"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"047dfb4e757f42c08129c8c7c5daf4bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2171f26cabc84f4cacee2874c6b27145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94d14ed048614aa7ada8191a9a36cb2f"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 1,477,635 || all params: 185,902,086 || trainable%: 0.7948\n  base_model.model.classifier.original_module.weight: requires_grad=False\n  base_model.model.classifier.original_module.bias: requires_grad=False\n  base_model.model.classifier.modules_to_save.default.weight: requires_grad=True\n  base_model.model.classifier.modules_to_save.default.bias: requires_grad=True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e57193df36354e1bbd45de65c406e660"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251211_162050-qj1ufdgl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/qj1ufdgl' target=\"_blank\">deberta-base-lora-r16-r2</a></strong> to <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI' target=\"_blank\">https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/qj1ufdgl' target=\"_blank\">https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/qj1ufdgl</a>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_47/170199.py:156: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3555' max='3555' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3555/3555 1:01:44, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.418700</td>\n      <td>1.434995</td>\n      <td>0.413000</td>\n      <td>0.405546</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.340400</td>\n      <td>1.446729</td>\n      <td>0.431000</td>\n      <td>0.425039</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.300500</td>\n      <td>1.368116</td>\n      <td>0.470000</td>\n      <td>0.468253</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.302400</td>\n      <td>1.463528</td>\n      <td>0.475000</td>\n      <td>0.471447</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.274000</td>\n      <td>1.534731</td>\n      <td>0.475000</td>\n      <td>0.472377</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"  Pred distribution: {0: 412, 1: 365, 2: 223}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 435, 1: 320, 2: 245}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 380, 1: 338, 2: 282}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 393, 1: 354, 2: 253}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 389, 1: 345, 2: 266}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"  Pred distribution: {0: 410, 1: 331, 2: 259}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 410, 1: 331, 2: 259}\n\nTEST RESULTS → ACC=0.5030, F1=0.4992\n\nClassification Report:\n               precision    recall  f1-score   support\n\n   Entailment       0.50      0.61      0.55       334\n      Neutral       0.51      0.50      0.51       333\nContradiction       0.51      0.40      0.45       333\n\n     accuracy                           0.50      1000\n    macro avg       0.50      0.50      0.50      1000\n weighted avg       0.50      0.50      0.50      1000\n\n\n Saving model to: /kaggle/working/ANLI_Experiments/deberta-base-lora-r16-r2/final_model\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/ANLI_Experiments/deberta-base-lora-r16-r2/final_model)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"\n Uploading model to W&B Artifacts...\n Model uploaded to W&B Artifacts: model-deberta-base-lora-r16-r2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▂▅▆▆█</td></tr><tr><td>eval/f1_macro</td><td>▁▂▆▆▆█</td></tr><tr><td>eval/loss</td><td>▃▄▁▄▇█</td></tr><tr><td>eval/runtime</td><td>▁█▄▁▁▃</td></tr><tr><td>eval/samples_per_second</td><td>█▁▅██▆</td></tr><tr><td>eval/steps_per_second</td><td>█▁▅██▆</td></tr><tr><td>test/accuracy</td><td>▁▁</td></tr><tr><td>test/f1_contradiction</td><td>▁</td></tr><tr><td>test/f1_entailment</td><td>▁</td></tr><tr><td>test/f1_macro</td><td>▁▁</td></tr><tr><td>test/f1_neutral</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▁▁▄▄▃▅▇▄▆▄▅▄▆▆▇▄▃▄▅▆▂▃▆▄▆▆▄▄▆▅▄▆▄▅██▆▆▅▄</td></tr><tr><td>train/learning_rate</td><td>▂▃▄▇█▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>██▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_time_min</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.503</td></tr><tr><td>eval/f1_macro</td><td>0.49922</td></tr><tr><td>eval/loss</td><td>1.57154</td></tr><tr><td>eval/runtime</td><td>6.5734</td></tr><tr><td>eval/samples_per_second</td><td>152.129</td></tr><tr><td>eval/steps_per_second</td><td>2.434</td></tr><tr><td>test/accuracy</td><td>0.503</td></tr><tr><td>test/f1_contradiction</td><td>0.44595</td></tr><tr><td>test/f1_entailment</td><td>0.5457</td></tr><tr><td>test/f1_macro</td><td>0.49922</td></tr><tr><td>test/f1_neutral</td><td>0.50602</td></tr><tr><td>test/loss</td><td>1.57154</td></tr><tr><td>test/runtime</td><td>6.6042</td></tr><tr><td>test/samples_per_second</td><td>151.42</td></tr><tr><td>test/steps_per_second</td><td>2.423</td></tr><tr><td>total_flos</td><td>1.437422658187752e+16</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>3555</td></tr><tr><td>train/grad_norm</td><td>88136.33594</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.274</td></tr><tr><td>train_loss</td><td>0.38303</td></tr><tr><td>train_runtime</td><td>3707.5425</td></tr><tr><td>train_samples_per_second</td><td>61.307</td></tr><tr><td>train_steps_per_second</td><td>0.959</td></tr><tr><td>train_time_min</td><td>61.8004</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">deberta-base-lora-r16-r2</strong> at: <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/qj1ufdgl' target=\"_blank\">https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/qj1ufdgl</a><br> View project at: <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI' target=\"_blank\">https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI</a><br>Synced 5 W&B file(s), 1 media file(s), 12 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251211_162050-qj1ufdgl/logs</code>"},"metadata":{}},{"name":"stdout","text":"\nFINAL RESULTS: {'run_name': 'deberta-base-lora-r16-r2', 'accuracy': 0.503, 'f1_macro': 0.4992229890208902, 'train_time': 61.8003990372022}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"WANDB_RUN_NAME = \"roberta-large-lora-r16-r2\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T21:22:00.682774Z","iopub.execute_input":"2025-12-11T21:22:00.683127Z","iopub.status.idle":"2025-12-11T21:22:00.697663Z","shell.execute_reply.started":"2025-12-11T21:22:00.683081Z","shell.execute_reply":"2025-12-11T21:22:00.696774Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\nOUTPUT_BASE = \"/kaggle/working/ANLI_Experiments\"\nos.makedirs(OUTPUT_BASE, exist_ok=True)\n\n\n\nresults = run_experiment(\n    model_name=\"FacebookAI/roberta-large\",\n    use_lora=True,\n    lora_r=16,\n    num_epochs=4,\n    dataset_config=\"r2\",\n    run_name=\"roberta-large-lora-r16-r2\",\n    tags=[\"RoBERTa\", \"LoRA\", \"R2\"],\n)\n\nprint(f\"\\nFINAL RESULTS: {results}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T21:22:57.688173Z","iopub.execute_input":"2025-12-11T21:22:57.689171Z","iopub.status.idle":"2025-12-11T23:35:48.657974Z","shell.execute_reply.started":"2025-12-11T21:22:57.689136Z","shell.execute_reply":"2025-12-11T23:35:48.657362Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\n Starting Run: roberta-large-lora-r16-r2\n============================================================\nR2 train: 45460 samples\nTOTAL training samples = 45460\nLabel distribution: Counter({1: 20959, 0: 14448, 2: 10053})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8733986480e48109bb0a18d2be73fb5"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 3,411,971 || all params: 358,774,790 || trainable%: 0.9510\n  base_model.model.classifier.original_module.dense.weight: requires_grad=False\n  base_model.model.classifier.original_module.dense.bias: requires_grad=False\n  base_model.model.classifier.original_module.out_proj.weight: requires_grad=False\n  base_model.model.classifier.original_module.out_proj.bias: requires_grad=False\n  base_model.model.classifier.modules_to_save.default.dense.weight: requires_grad=True\n  base_model.model.classifier.modules_to_save.default.dense.bias: requires_grad=True\n  base_model.model.classifier.modules_to_save.default.out_proj.weight: requires_grad=True\n  base_model.model.classifier.modules_to_save.default.out_proj.bias: requires_grad=True\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251211_212259-w7i998ak</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/w7i998ak' target=\"_blank\">roberta-large-lora-r16-r2</a></strong> to <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI' target=\"_blank\">https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/w7i998ak' target=\"_blank\">https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/w7i998ak</a>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_47/2011258393.py:156: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2844' max='2844' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2844/2844 2:11:54, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.408300</td>\n      <td>1.630409</td>\n      <td>0.384000</td>\n      <td>0.356285</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.300000</td>\n      <td>1.601632</td>\n      <td>0.403000</td>\n      <td>0.393978</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.275700</td>\n      <td>1.622100</td>\n      <td>0.413000</td>\n      <td>0.408529</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.267000</td>\n      <td>1.754698</td>\n      <td>0.406000</td>\n      <td>0.399526</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"  Pred distribution: {0: 517, 1: 343, 2: 140}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 457, 1: 297, 2: 246}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 405, 1: 332, 2: 263}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 410, 1: 343, 2: 247}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"  Pred distribution: {0: 425, 1: 329, 2: 246}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Pred distribution: {0: 425, 1: 329, 2: 246}\n\nTEST RESULTS → ACC=0.4210, F1=0.4145\n\nClassification Report:\n               precision    recall  f1-score   support\n\n   Entailment       0.42      0.53      0.47       334\n      Neutral       0.46      0.46      0.46       333\nContradiction       0.37      0.28      0.32       333\n\n     accuracy                           0.42      1000\n    macro avg       0.42      0.42      0.41      1000\n weighted avg       0.42      0.42      0.41      1000\n\n\n Saving model to: /kaggle/working/ANLI_Experiments/roberta-large-lora-r16-r2/final_model\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/ANLI_Experiments/roberta-large-lora-r16-r2/final_model)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"\n Uploading model to W&B Artifacts...\n Model uploaded to W&B Artifacts: model-roberta-large-lora-r16-r2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▅█</td></tr><tr><td>eval/f1_macro</td><td>▁▆▇▆█</td></tr><tr><td>eval/loss</td><td>▂▁▂█▂</td></tr><tr><td>eval/runtime</td><td>▁▅▁▅█</td></tr><tr><td>eval/samples_per_second</td><td>█▄█▃▁</td></tr><tr><td>eval/steps_per_second</td><td>█▄█▃▁</td></tr><tr><td>test/accuracy</td><td>▁▁</td></tr><tr><td>test/f1_contradiction</td><td>▁</td></tr><tr><td>test/f1_entailment</td><td>▁</td></tr><tr><td>test/f1_macro</td><td>▁▁</td></tr><tr><td>test/f1_neutral</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▁▃█▂▅▇▃▆▃▇▂▂▃▄▁▁▁▂▂▃▂▄▃▂▁▄▁▃▃▂▂▅▄▃▃▁▄▅▃▃</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▆▇████▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_time_min</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.421</td></tr><tr><td>eval/f1_macro</td><td>0.41447</td></tr><tr><td>eval/loss</td><td>1.61822</td></tr><tr><td>eval/runtime</td><td>19.8532</td></tr><tr><td>eval/samples_per_second</td><td>50.37</td></tr><tr><td>eval/steps_per_second</td><td>0.806</td></tr><tr><td>test/accuracy</td><td>0.421</td></tr><tr><td>test/f1_contradiction</td><td>0.31779</td></tr><tr><td>test/f1_entailment</td><td>0.4664</td></tr><tr><td>test/f1_macro</td><td>0.41447</td></tr><tr><td>test/f1_neutral</td><td>0.45921</td></tr><tr><td>test/loss</td><td>1.61822</td></tr><tr><td>test/runtime</td><td>19.8735</td></tr><tr><td>test/samples_per_second</td><td>50.318</td></tr><tr><td>test/steps_per_second</td><td>0.805</td></tr><tr><td>total_flos</td><td>4.526989915705344e+16</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>train/global_step</td><td>2844</td></tr><tr><td>train/grad_norm</td><td>187972.64062</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.267</td></tr><tr><td>train_loss</td><td>0.372</td></tr><tr><td>train_runtime</td><td>7919.101</td></tr><tr><td>train_samples_per_second</td><td>22.962</td></tr><tr><td>train_steps_per_second</td><td>0.359</td></tr><tr><td>train_time_min</td><td>131.99351</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">roberta-large-lora-r16-r2</strong> at: <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/w7i998ak' target=\"_blank\">https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI/runs/w7i998ak</a><br> View project at: <a href='https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI' target=\"_blank\">https://wandb.ai/capcool79-northeastern-university/EAI-Assignment-Multi-class-classification-using-ANLI</a><br>Synced 5 W&B file(s), 1 media file(s), 12 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251211_212259-w7i998ak/logs</code>"},"metadata":{}},{"name":"stdout","text":"\nFINAL RESULTS: {'run_name': 'roberta-large-lora-r16-r2', 'accuracy': 0.421, 'f1_macro': 0.4144689851494887, 'train_time': 131.99350779453914}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}